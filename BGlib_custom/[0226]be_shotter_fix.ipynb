{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Raw_Data\": shape (100, 54560), type \"<c8\">\n",
      "located at: \n",
      "\t/Measurement_000/Channel_000/Raw_Data \n",
      "Data contains: \n",
      "\tquantity (a.u.) \n",
      "Data dimensions and original shape: \n",
      "Position Dimensions: \n",
      "\tX - size: 10 \n",
      "\tY - size: 10 \n",
      "Spectroscopic Dimensions: \n",
      "\tFrequency - size: 124 \n",
      "\tField - size: 2 \n",
      "\twrite_bias - size: 20 \n",
      "\tread_bias - size: 11\n",
      "Data Type:\n",
      "\tcomplex64\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pyUSID\n",
    "\n",
    "# 아래 출력은 html과 같지만 구조가 달라 삭제함\n",
    "hf = h5py.File('pyusid.h5','r+')\n",
    "h5_main = pyUSID.hdf_utils.find_dataset(hf, 'Raw_Data')[0]\n",
    "print(h5_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 54560), type \"<f4\"> 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# get_frequency_vector\n",
    "h5_spec_vals = h5_main.h5_spec_vals\n",
    "freq_dim = np.argwhere('Frequency' == np.array(h5_main.spec_dim_labels)).squeeze()\n",
    "\n",
    "print(h5_spec_vals,freq_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 123, 123, 123], dtype=uint32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_main.h5_spec_inds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dim_ind = h5_main.spec_dim_labels.index('Frequency')\n",
    "step_start_inds = np.where(h5_main.h5_spec_inds[freq_dim_ind] == 0)[0]\n",
    "\n",
    "freq_dim_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54560"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h5_main.h5_spec_inds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(step_start_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_start_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_vec = h5_spec_vals[freq_dim,step_start_inds[0]:step_start_inds[1]]\n",
    "freq_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Raw_Data\": shape (100, 54560), type \"<c8\">\n",
      "located at: \n",
      "\t/Measurement_000/Channel_000/Raw_Data \n",
      "Data contains: \n",
      "\tquantity (a.u.) \n",
      "Data dimensions and original shape: \n",
      "Position Dimensions: \n",
      "\tY - size: 10 \n",
      "\tX - size: 10 \n",
      "Spectroscopic Dimensions: \n",
      "\tread_bias - size: 11 \n",
      "\twrite_bias - size: 20 \n",
      "\tField - size: 2 \n",
      "\tFrequency - size: 124\n",
      "Data Type:\n",
      "\tcomplex64\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pyUSID\n",
    "hf = h5py.File('pyusid.h5','r+')\n",
    "h5_main = pyUSID.hdf_utils.find_dataset(hf, 'Raw_Data')[0]\n",
    "print(h5_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 54560), type \"<f4\"> 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "h5_spec_vals = h5_main.h5_spec_vals\n",
    "freq_dim = np.argwhere('Frequency' == np.array(h5_main.spec_dim_labels)).squeeze()\n",
    "\n",
    "print(h5_spec_vals,freq_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['read_bias', 'write_bias', 'Field', 'Frequency'], dtype='<U10')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(h5_main.spec_dim_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dim_ind = h5_main.spec_dim_labels.index('Frequency')\n",
    "step_start_inds = np.where(h5_main.h5_spec_inds[freq_dim_ind] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(step_start_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2, ..., 121, 122, 123], dtype=uint32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_main.h5_spec_inds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54560"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h5_main.h5_spec_inds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123,   0], dtype=uint32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_main.h5_spec_inds[3][0:125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   124,   248,   372,   496,   620,   744,   868,   992,\n",
       "        1116,  1240,  1364,  1488,  1612,  1736,  1860,  1984,  2108,\n",
       "        2232,  2356,  2480,  2604,  2728,  2852,  2976,  3100,  3224,\n",
       "        3348,  3472,  3596,  3720,  3844,  3968,  4092,  4216,  4340,\n",
       "        4464,  4588,  4712,  4836,  4960,  5084,  5208,  5332,  5456,\n",
       "        5580,  5704,  5828,  5952,  6076,  6200,  6324,  6448,  6572,\n",
       "        6696,  6820,  6944,  7068,  7192,  7316,  7440,  7564,  7688,\n",
       "        7812,  7936,  8060,  8184,  8308,  8432,  8556,  8680,  8804,\n",
       "        8928,  9052,  9176,  9300,  9424,  9548,  9672,  9796,  9920,\n",
       "       10044, 10168, 10292, 10416, 10540, 10664, 10788, 10912, 11036,\n",
       "       11160, 11284, 11408, 11532, 11656, 11780, 11904, 12028, 12152,\n",
       "       12276, 12400, 12524, 12648, 12772, 12896, 13020, 13144, 13268,\n",
       "       13392, 13516, 13640, 13764, 13888, 14012, 14136, 14260, 14384,\n",
       "       14508, 14632, 14756, 14880, 15004, 15128, 15252, 15376, 15500,\n",
       "       15624, 15748, 15872, 15996, 16120, 16244, 16368, 16492, 16616,\n",
       "       16740, 16864, 16988, 17112, 17236, 17360, 17484, 17608, 17732,\n",
       "       17856, 17980, 18104, 18228, 18352, 18476, 18600, 18724, 18848,\n",
       "       18972, 19096, 19220, 19344, 19468, 19592, 19716, 19840, 19964,\n",
       "       20088, 20212, 20336, 20460, 20584, 20708, 20832, 20956, 21080,\n",
       "       21204, 21328, 21452, 21576, 21700, 21824, 21948, 22072, 22196,\n",
       "       22320, 22444, 22568, 22692, 22816, 22940, 23064, 23188, 23312,\n",
       "       23436, 23560, 23684, 23808, 23932, 24056, 24180, 24304, 24428,\n",
       "       24552, 24676, 24800, 24924, 25048, 25172, 25296, 25420, 25544,\n",
       "       25668, 25792, 25916, 26040, 26164, 26288, 26412, 26536, 26660,\n",
       "       26784, 26908, 27032, 27156, 27280, 27404, 27528, 27652, 27776,\n",
       "       27900, 28024, 28148, 28272, 28396, 28520, 28644, 28768, 28892,\n",
       "       29016, 29140, 29264, 29388, 29512, 29636, 29760, 29884, 30008,\n",
       "       30132, 30256, 30380, 30504, 30628, 30752, 30876, 31000, 31124,\n",
       "       31248, 31372, 31496, 31620, 31744, 31868, 31992, 32116, 32240,\n",
       "       32364, 32488, 32612, 32736, 32860, 32984, 33108, 33232, 33356,\n",
       "       33480, 33604, 33728, 33852, 33976, 34100, 34224, 34348, 34472,\n",
       "       34596, 34720, 34844, 34968, 35092, 35216, 35340, 35464, 35588,\n",
       "       35712, 35836, 35960, 36084, 36208, 36332, 36456, 36580, 36704,\n",
       "       36828, 36952, 37076, 37200, 37324, 37448, 37572, 37696, 37820,\n",
       "       37944, 38068, 38192, 38316, 38440, 38564, 38688, 38812, 38936,\n",
       "       39060, 39184, 39308, 39432, 39556, 39680, 39804, 39928, 40052,\n",
       "       40176, 40300, 40424, 40548, 40672, 40796, 40920, 41044, 41168,\n",
       "       41292, 41416, 41540, 41664, 41788, 41912, 42036, 42160, 42284,\n",
       "       42408, 42532, 42656, 42780, 42904, 43028, 43152, 43276, 43400,\n",
       "       43524, 43648, 43772, 43896, 44020, 44144, 44268, 44392, 44516,\n",
       "       44640, 44764, 44888, 45012, 45136, 45260, 45384, 45508, 45632,\n",
       "       45756, 45880, 46004, 46128, 46252, 46376, 46500, 46624, 46748,\n",
       "       46872, 46996, 47120, 47244, 47368, 47492, 47616, 47740, 47864,\n",
       "       47988, 48112, 48236, 48360, 48484, 48608, 48732, 48856, 48980,\n",
       "       49104, 49228, 49352, 49476, 49600, 49724, 49848, 49972, 50096,\n",
       "       50220, 50344, 50468, 50592, 50716, 50840, 50964, 51088, 51212,\n",
       "       51336, 51460, 51584, 51708, 51832, 51956, 52080, 52204, 52328,\n",
       "       52452, 52576, 52700, 52824, 52948, 53072, 53196, 53320, 53444,\n",
       "       53568, 53692, 53816, 53940, 54064, 54188, 54312, 54436],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_start_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes results to the HDF5 file\n",
      "\tThis class (likely) supports interruption and resuming of computations!\n",
      "\tIf you are operating in a python console, press Ctrl+C or Cmd+C to abort\n",
      "\tIf you are in a Jupyter notebook, click on \"Kernel\">>\"Interrupt\"\n",
      "\tIf you are operating on a cluster and your job gets killed, re-run the job to resume\n",
      "\n",
      "Rank 0 finished parallel computation\n",
      "Rank 0 - 100% complete. Time remaining: 0.0 msec\n",
      "Finished processing the entire dataset!\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (4 members)>]\n",
      "Resuming computation. 0% completed already\n",
      "\tThis class (likely) supports interruption and resuming of computations!\n",
      "\tIf you are operating in a python console, press Ctrl+C or Cmd+C to abort\n",
      "\tIf you are in a Jupyter notebook, click on \"Kernel\">>\"Interrupt\"\n",
      "\tIf you are operating on a cluster and your job gets killed, re-run the job to resume\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\test_pycroscopy\\bglib\\BGlib\\be\\analysis\\fitter.py:140: UserWarning: status dataset not created yet\n",
      "  warn('status dataset not created yet')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - 100% complete. Time remaining: 0.0 msec\n",
      "Finished processing the entire dataset!\n"
     ]
    }
   ],
   "source": [
    "from BGlib import be as belib\n",
    "\n",
    "sho_fitter = belib.analysis.BESHOfitter(h5_main, cores=None, verbose=False, h5_target_group=hf)\n",
    "sho_fitter.set_up_guess(guess_func=belib.analysis.be_sho_fitter.SHOGuessFunc.complex_gaussian,\n",
    "                        num_points=5)\n",
    "h5_sho_guess = sho_fitter.do_guess(override=True)\n",
    "sho_fitter.set_up_fit()\n",
    "h5_sho_fit = sho_fitter.do_fit(override=True)\n",
    "h5_sho_grp = h5_sho_fit.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Fit\": shape (100, 440), type \"|V40\">\n",
       "located at: \n",
       "\t/Raw_Data-SHO_Fit_000/Fit \n",
       "Data contains: \n",
       "\tSHO (compound) \n",
       "Data dimensions and original shape: \n",
       "Position Dimensions: \n",
       "\tY - size: 10 \n",
       "\tX - size: 10 \n",
       "Spectroscopic Dimensions: \n",
       "\tread_bias - size: 11 \n",
       "\twrite_bias - size: 20 \n",
       "\tField - size: 2\n",
       "Data Fields:\n",
       "\tAmplitude [V], Frequency [Hz], Quality Factor, Phase [rad], R2 Criterion"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_sho_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "      ├ completed_fit_positions\n",
      "      ├ completed_guess_positions\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "├ Raw_Data-SHO_Fit_000\n",
      "  --------------------\n",
      "  ├ Fit\n",
      "  ├ Guess\n",
      "  ├ Spectroscopic_Indices\n",
      "  ├ Spectroscopic_Values\n",
      "  ├ completed_fit_positions\n",
      "  ├ completed_guess_positions\n"
     ]
    }
   ],
   "source": [
    "import pyUSID as usid\n",
    "import h5py\n",
    "\n",
    "usid.hdf_utils.print_tree(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "      ├ completed_fit_positions\n",
      "      ├ completed_guess_positions\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "├ Raw_Data-SHO_Fit_000\n",
      "  --------------------\n",
      "  ├ Fit\n",
      "  ├ Guess\n",
      "  ├ Spectroscopic_Indices\n",
      "  ├ Spectroscopic_Values\n",
      "  ├ completed_fit_positions\n",
      "  ├ completed_guess_positions\n"
     ]
    }
   ],
   "source": [
    "# sho_fit 이 Channel_000안에 있는 것을 확인하여 이동\n",
    "hf.copy('/Raw_Data-SHO_Fit_000','/Measurement_000/Channel_000/Raw_Data-SHO_Fit_000')\n",
    "usid.hdf_utils.print_tree(hf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "      ├ completed_fit_positions\n",
      "      ├ completed_guess_positions\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "del hf['/Raw_Data-SHO_Fit_000']\n",
    "usid.hdf_utils.print_tree(hf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "      ├ completed_fit_positions\n",
      "      ├ completed_guess_positions\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "usid.hdf_utils.print_tree(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd_mat shape =  (10, 10, 11, 20, 2)\n",
      "Phase offset [rad] =  0.1405820995569229\n"
     ]
    }
   ],
   "source": [
    "Nd_mat = h5_sho_fit.get_n_dim_form()\n",
    "print('Nd_mat shape = ', Nd_mat.shape)\n",
    "\n",
    "phase_offset = Nd_mat[0, 0, 1, 0, 0]['Phase [rad]']\n",
    "\n",
    "print('Phase offset [rad] = ', phase_offset)\n",
    "\n",
    "Nd_mat[:,:,:,:,:]['Phase [rad]'] = Nd_mat[:,:,:,:,:]['Phase [rad]'] - phase_offset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
